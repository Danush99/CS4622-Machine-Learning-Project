{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler # eliminate outliers\n",
    "from sklearn import svm\n",
    "import warnings                   # To ignore the warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "valid = pd.read_csv('valid.csv')\n",
    "\n",
    "# Find columns with missing values and count how many missing values in each column\n",
    "missing_columns = train.columns[train.isnull().any()]\n",
    "missing_counts = train[missing_columns].isnull().sum()\n",
    "\n",
    "# Print the columns with missing values and their corresponding missing value counts\n",
    "print(\"shape of train: \", train.shape)\n",
    "for column in missing_columns:\n",
    "    print(f\"Column '{column}' has {missing_counts[column]} missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label 2 contains missing values in the training dataset, but given that the dataset has almost 30,000 rows, removing 480 rows with missing values doesn't significantly impact the dataset's overall size or quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = \"label_1\" #Speaker ID\n",
    "L2 = \"label_2\" #Speaker age\n",
    "L3 = \"label_3\" #Speaker gender\n",
    "L4 = \"label_4\" #Speaker accent\n",
    "LABELS = [L1, L2, L3, L4,]\n",
    "AGE_LABEL = L2\n",
    "FEATURES = [f'feature_{i}' for i in range(1,769)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.copy()\n",
    "test_df = test.copy()\n",
    "valid_df = valid.copy()\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[LABELS + [FEATURES[i] for i in range(0,267,32)]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = {}\n",
    "x_valid = {}\n",
    "x_test = {}\n",
    "\n",
    "y_train = {}\n",
    "y_valid = {}\n",
    "y_test = {}\n",
    "\n",
    "#create dictionaries for each label\n",
    "for target_label in LABELS:\n",
    "  tr_df = train_df[train_df['label_2'].notna()] if target_label == \"label_2\" else train_df\n",
    "  vl_df = valid_df[valid_df['label_2'].notna()] if target_label == \"label_2\" else valid_df\n",
    "  te_df = test_df\n",
    "\n",
    "  scaler = RobustScaler()\n",
    "  # x_train_features = tr_df.drop(LABELS, axis=1)\n",
    "\n",
    "  x_train[target_label] = pd.DataFrame(scaler.fit_transform(tr_df.drop(LABELS, axis=1)), columns=FEATURES)\n",
    "  y_train[target_label] = tr_df[target_label]\n",
    "\n",
    "  x_valid[target_label] = pd.DataFrame(scaler.transform(vl_df.drop(LABELS, axis=1)), columns=FEATURES)\n",
    "  y_valid  [target_label] = vl_df[target_label]\n",
    "\n",
    "  x_test[target_label] = pd.DataFrame(scaler.transform(te_df.drop([\"ID\"],axis=1)), columns=FEATURES)\n",
    "  # y_test[target_label] = te_df[target_label] <- need to predict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the provided code, it removes rows with NaN values in Label 2. All four labels are then organized into a dictionary for easier handling and convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation(model, x_train, y_train):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, x_train, y_train, cv=kf)\n",
    "\n",
    "    mean_accuracy = scores.mean()\n",
    "    std_accuracy = scores.std()\n",
    "    # Print the cross-validation scores\n",
    "    model_name = type(model).__name__\n",
    "    print('--',model_name,'--')\n",
    "    print(\"Cross-validation scores:\", scores)\n",
    "    print(f\"Standard Deviation: {std_accuracy:.2f}\")\n",
    "    print(\"***Mean Accuracy***: {:.2f}%\".format(mean_accuracy * 100))\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search for hyper parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSearch(modelName, x_train, y_train):\n",
    "\n",
    "    param_dist_svm = {\n",
    "        'C': [100,10,1],\n",
    "        'kernel': ['rbf','linear','poly','sigmoid'],\n",
    "        'gamma': ['scale','auto',1,10],\n",
    "        'degree': [1,2,3],  # For the polynomial kernel\n",
    "        'class_weight' : ['None','balanced']\n",
    "    }\n",
    "\n",
    "    param_dist_catBoost = {\n",
    "        'depth': [2,6,10],\n",
    "        'learning_rate': [0.1,1,10],\n",
    "        'l2_leaf_reg': [1,2],\n",
    "        'random_strength': [0,1],\n",
    "    }\n",
    "\n",
    "    param_dist_randomForrest = {\n",
    "        'n_estimators': [1,10,100],\n",
    "        'max_depth': [1,10],\n",
    "        'min_samples_split': [1,10],\n",
    "        'min_samples_leaf': [1,10],\n",
    "    }\n",
    "\n",
    "    svm = SVC()\n",
    "    catBoost = CatBoostClassifier(iterations=100,task_type=\"GPU\",devices='0:1')\n",
    "    randomForrest = RandomForestClassifier()\n",
    "\n",
    "    model = ''\n",
    "    param_dist = ''\n",
    "    nJobs = -1\n",
    "\n",
    "    if(modelName==\"svm\"):\n",
    "        model = svm\n",
    "        param_dist = param_dist_svm\n",
    "        nJobs = -1\n",
    "    elif(modelName==\"catBoost\"):\n",
    "        model = catBoost\n",
    "        param_dist = param_dist_catBoost\n",
    "        nJobs = 1\n",
    "    elif(modelName==\"randomForest\"):\n",
    "        model = randomForrest\n",
    "        param_dist = param_dist_randomForrest\n",
    "        nJobs = -1\n",
    "\n",
    "    \n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        model, param_distributions=param_dist, n_iter=10, cv=5, n_jobs=nJobs, random_state=42, scoring='accuracy'\n",
    "    )\n",
    "\n",
    "    random_search.fit(x_train, y_train)\n",
    "\n",
    "    best_params = random_search.best_params_\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    print(\"best parameters:\", best_params)\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for hyper parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(modelName, param_grid, model, x_train, y_train):\n",
    "    nJobs = -1\n",
    "    if(modelName==\"svm\"):\n",
    "        nJobs = -1\n",
    "    elif(modelName==\"catBoost\"):\n",
    "        nJobs = 1\n",
    "    elif(modelName==\"randomForest\"):\n",
    "        nJobs = -1\n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=nJobs, verbose=3)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_param_grid(best_params, modelName):\n",
    "    param_grid = {}\n",
    "\n",
    "    if modelName == 'svc' or 'svm' :\n",
    "        param_grid = {\n",
    "            'kernel': [best_params['kernel']],\n",
    "            'gamma': ['scale', 'auto'] if best_params['gamma'] == 'scale' else [best_params['gamma']],\n",
    "            'degree': [best_params['degree']],\n",
    "            'class_weight': [best_params['class_weight']],\n",
    "            'C': [ best_params['C'], 2*int(best_params['C']) ]\n",
    "        }\n",
    "    elif modelName == 'catBoost' :\n",
    "        param_grid = {\n",
    "            'depth': [ best_params['depth']-1, best_params['depth'], best_params['depth']+1 ],\n",
    "            'learning_rate': [ best_params['learning_rate'], int(best_params['learning_rate'])*2 ],\n",
    "            'l2_leaf_reg': [best_params['l2_leaf_reg']],\n",
    "            'random_strength': [best_params['random_strength']],\n",
    "        }\n",
    "    elif modelName == 'randomForest' :\n",
    "        param_grid = {\n",
    "            'n_estimators': [best_params['n_estimators'], int(best_params['n_estimators'])*2],\n",
    "            'max_depth': [best_params['max_depth'], int(best_params['max_depth'])*2],\n",
    "            'min_samples_split': [best_params['min_samples_split']],\n",
    "            'min_samples_leaf': [best_params['min_samples_leaf']],\n",
    "        }\n",
    "    \n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv_from_labels(y_valid_pred, output_file):\n",
    "    # Create a DataFrame with the label data\n",
    "\n",
    "    data = {\n",
    "        'ID': range(1, len(y_valid_pred[0]) + 1),\n",
    "        'label_1': y_valid_pred[0],  # Assuming label_1 is the first column in y_valid_pred\n",
    "        'label_2': y_valid_pred[1],  # Assuming label_2 is the second column in y_valid_pred\n",
    "        'label_3': y_valid_pred[2],  # Assuming label_3 is the third column in y_valid_pred\n",
    "        'label_4': y_valid_pred[3]   # Assuming label_4 is the fourth column in y_valid_pred\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTrain( model, x_train, y_train, x_valid=None, y_valid=None, x_test=None):\n",
    "    # Train\n",
    "    model.fit(x_train, y_train)\n",
    "    y_test_pred = False\n",
    "    model_name = type(model).__name__\n",
    "\n",
    "    if(not x_valid.empty):\n",
    "        # Predict\n",
    "        y_valid_pred = model.predict(x_valid)\n",
    "        # Accuracy\n",
    "        print(model_name,\"accuracy_score for validation data set: \",metrics.accuracy_score(y_valid, y_valid_pred))\n",
    "\n",
    "    if(not x_test.empty):\n",
    "        ########### TEST ##############\n",
    "        y_test_pred = model.predict(x_test)\n",
    "\n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels=[]\n",
    "# This array is using to create the final output csv of all predicted labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = L1\n",
    "pca_NComponents = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the dataset is bias or not\n",
    "print(train_df[Label].unique())\n",
    "print(train_df[Label].value_counts())\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above information label 1 is not bias and its not compulsory to do over-sampling a under-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = x_train[Label].copy()\n",
    "y_train_df = y_train[Label].copy()\n",
    "\n",
    "x_valid_df = x_valid[Label].copy()\n",
    "y_valid_df = y_valid[Label].copy()\n",
    "\n",
    "x_test_df = x_test[Label].copy()\n",
    "# y_test__df = y_test[L1].copy() <- need to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction (dimension reduction)\n",
    "pca = PCA(n_components=pca_NComponents, svd_solver='full')\n",
    "pca.fit(x_train_df)\n",
    "x_train_df_pca = pd.DataFrame(pca.transform(x_train_df)) #train\n",
    "x_valid_df_pca = pd.DataFrame(pca.transform(x_valid_df)) #valid\n",
    "x_test_df_pca = pd.DataFrame(pca.transform(x_test_df)) #test\n",
    "print('Shape after PCA: ',x_train_df_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, it is necessary to select the best classification algorithm for model training. Therefore, cross-validation techniques have been used to choose the best classifier. Four different classifiers have been applied for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before feature engineering cross validation and checking accuracy\n",
    "\n",
    "svm_classifier = svm.SVC()\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "catBoost_classifier = CatBoostClassifier(iterations=100,task_type=\"GPU\")\n",
    "randomForest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "crossValidation(svm_classifier, x_train_df, y_train_df)\n",
    "crossValidation(knn_classifier, x_train_df, y_train_df)\n",
    "crossValidation(catBoost_classifier, x_train_df, y_train_df)\n",
    "crossValidation(randomForest_classifier, x_train_df, y_train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm - 92.82% <br/>\n",
    "knn - nan% <br/>\n",
    "catBoost - 84.45% <br/>\n",
    "random forrest - 84.96% <br/>\n",
    "Therefore SVM is the best classifier to use further stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After dimension reduction (with PCA) cross validation and checking accuracy\n",
    "crossValidation(svm_classifier, x_train_df_pca, y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the previous observation, the accuracy has not significantly decreased even though PCA has been applied. Therefore, the dataset that underwent PCA is being used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning with random search \n",
    "best_params_from_random_search = randomSearch('svm', x_train_df_pca, y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search selects the best hyper-parameters for the chosen classifier randomly. Using these parameters, create a suitable parameter grid for grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning with grid search \n",
    "param_dist_svm = generate_param_grid(best_params_from_random_search, 'svm')\n",
    "\n",
    "gridSearch('svm', param_dist_svm, svm_classifier, x_train_df_pca, y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination of random search followed by grid search strikes a balance between exploration and exploitation of the hyperparameter space, making hyperparameter tuning more efficient and effective in finding good model configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = svm.SVC(kernel='rbf', C=1, class_weight='balanced')\n",
    "\n",
    "#predict for the test dataset\n",
    "y_test_pred = modelTrain(svm_classifier, x_train_df_pca, y_train_df, x_valid_df_pca, y_valid_df, x_test_df_pca)\n",
    "\n",
    "all_labels.append(y_test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = L2\n",
    "pca_NComponents = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the dataset is bias or not\n",
    "print(train_df[Label].unique())\n",
    "print(train_df[Label].value_counts())\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above information label 2 is not bias and its not compulsory to do over-sampling a under-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = x_train[Label].copy()\n",
    "y_train_df = y_train[Label].copy()\n",
    "\n",
    "x_valid_df = x_valid[Label].copy()\n",
    "y_valid_df = y_valid[Label].copy()\n",
    "\n",
    "x_test_df = x_test[Label].copy()\n",
    "# y_test__df = y_test[L1].copy() <- need to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction\n",
    "pca = PCA(n_components=pca_NComponents, svd_solver='full')\n",
    "pca.fit(x_train_df)\n",
    "x_train_df_pca = pd.DataFrame(pca.transform(x_train_df)) #train\n",
    "x_valid_df_pca = pd.DataFrame(pca.transform(x_valid_df)) #valid\n",
    "x_test_df_pca = pd.DataFrame(pca.transform(x_test_df)) #test\n",
    "print('Shape after PCA: ',x_train_df_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, it is necessary to select the best classification algorithm for model training. Therefore, cross-validation techniques have been used to choose the best classifier. Four different classifiers have been applied for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before feature engineering cross validation and checking accuracy\n",
    "\n",
    "svm_classifier = svm.SVC()\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "catBoost_classifier = CatBoostClassifier(iterations=100,task_type=\"GPU\")\n",
    "randomForest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "crossValidation(svm_classifier, x_train_df, y_train_df)\n",
    "crossValidation(knn_classifier, x_train_df, y_train_df)\n",
    "crossValidation(catBoost_classifier, x_train_df, y_train_df)\n",
    "crossValidation(randomForest_classifier, x_train_df, y_train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm - 92.82% <br/>\n",
    "knn - nan% <br/>\n",
    "catBoost - 84.45% <br/>\n",
    "random forrest - 84.96% <br/>\n",
    "Therefore SVM is the best classifier to use further stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After dimension reduction (with PCA) cross validation and checking accuracy\n",
    "crossValidation(svm_classifier, x_train_df_pca, y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the previous observation, the accuracy has not significantly decreased even though PCA has been applied. Therefore, the dataset that underwent PCA is being used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning with random search \n",
    "best_params_from_random_search = randomSearch('svm', x_train_df_pca, y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search selects the best hyper-parameters for the chosen classifier randomly. Using these parameters, create a suitable parameter grid for grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning with grid search \n",
    "param_dist_svm = generate_param_grid(best_params_from_random_search, 'svm')\n",
    "\n",
    "gridSearch('svm', param_dist_svm, svm_classifier, x_train_df_pca, y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination of random search followed by grid search strikes a balance between exploration and exploitation of the hyperparameter space, making hyperparameter tuning more efficient and effective in finding good model configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = svm.SVC(kernel='rbf', C=1, class_weight='balanced')\n",
    "\n",
    "y_test_pred = modelTrain(svm_classifier, x_train_df_pca, y_train_df, x_valid_df_pca, y_valid_df, x_test_df_pca)\n",
    "\n",
    "all_labels.append(y_test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = L3\n",
    "pca_NComponents = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the dataset is bias or not\n",
    "print(train_df[Label].unique())\n",
    "print(train_df[Label].value_counts())\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above information label 3 is bias to the value 1. Therefore, its necessary to do over-sampling and under-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = x_train[Label].copy()\n",
    "y_train_df = y_train[Label].copy()\n",
    "\n",
    "x_valid_df = x_valid[Label].copy()\n",
    "y_valid_df = y_valid[Label].copy()\n",
    "\n",
    "x_test_df = x_test[Label].copy()\n",
    "# y_test__df = y_test[L1].copy() <- need to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=pca_NComponents, svd_solver='full')\n",
    "pca.fit(x_train_df)\n",
    "x_train_df_pca = pd.DataFrame(pca.transform(x_train_df)) #train\n",
    "x_valid_df_pca = pd.DataFrame(pca.transform(x_valid_df)) #valid\n",
    "x_test_df_pca = pd.DataFrame(pca.transform(x_test_df)) #test\n",
    "print('Shape after PCA: ',x_train_df_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, it is necessary to select the best classification algorithm for model training. Therefore, cross-validation techniques have been used to choose the best classifier. Four different classifiers have been applied for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before feature engineering cross validation and checking accuracy\n",
    "\n",
    "svm_classifier = svm.SVC()\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "catBoost_classifier = CatBoostClassifier(iterations=100,task_type=\"GPU\")\n",
    "randomForest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "crossValidation(svm_classifier, x_train_df, y_train_df)\n",
    "crossValidation(knn_classifier, x_train_df, y_train_df)\n",
    "crossValidation(catBoost_classifier, x_train_df, y_train_df)\n",
    "crossValidation(randomForest_classifier, x_train_df, y_train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm - 92.82% <br/>\n",
    "knn - nan% <br/>\n",
    "catBoost - 84.45% <br/>\n",
    "random forrest - 84.96% <br/>\n",
    "Therefore SVM is the best classifier to use further stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After dimension reduction (with PCA) cross validation and checking accuracy\n",
    "crossValidation(svm_classifier, x_train_df_pca, y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the previous observation, the accuracy has not significantly decreased even though PCA has been applied. Therefore, the dataset that underwent PCA is being used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning with random search \n",
    "best_params_from_random_search = randomSearch('svm', x_train_df_pca, y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search selects the best hyper-parameters for the chosen classifier randomly. Using these parameters, create a suitable parameter grid for grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning with grid search \n",
    "param_dist_svm = generate_param_grid(best_params_from_random_search, 'svm')\n",
    "\n",
    "gridSearch('svm', param_dist_svm, svm_classifier, x_train_df_pca, y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination of random search followed by grid search strikes a balance between exploration and exploitation of the hyperparameter space, making hyperparameter tuning more efficient and effective in finding good model configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = svm.SVC(kernel='rbf', C=100, class_weight='balanced')\n",
    "\n",
    "y_test_pred = modelTrain(svm_classifier, x_train_df_pca, y_train_df, x_valid_df_pca, y_valid_df, x_test_df_pca)\n",
    "\n",
    "all_labels.append(y_test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = L4\n",
    "pca_NComponents = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the dataset is bias or not\n",
    "print(train_df[Label].unique())\n",
    "print(train_df[Label].value_counts())\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above information label 4 is bias to value 2 and 6. Therefore, its necessary to do over-sampling and under-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = x_train[Label].copy()\n",
    "y_train_df = y_train[Label].copy()\n",
    "\n",
    "x_valid_df = x_valid[Label].copy()\n",
    "y_valid_df = y_valid[Label].copy()\n",
    "\n",
    "x_test_df = x_test[Label].copy()\n",
    "# y_test__df = y_test[L1].copy() <- need to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=pca_NComponents, svd_solver='full')\n",
    "pca.fit(x_train_df)\n",
    "x_train_df_pca = pd.DataFrame(pca.transform(x_train_df)) #train\n",
    "x_valid_df_pca = pd.DataFrame(pca.transform(x_valid_df)) #valid\n",
    "x_test_df_pca = pd.DataFrame(pca.transform(x_test_df)) #test\n",
    "print('Shape after PCA: ',x_train_df_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, it is necessary to select the best classification algorithm for model training. Therefore, cross-validation techniques have been used to choose the best classifier. Four different classifiers have been applied for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before feature engineering cross validation and checking accuracy\n",
    "\n",
    "svm_classifier = svm.SVC()\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "catBoost_classifier = CatBoostClassifier(iterations=100,task_type=\"GPU\")\n",
    "randomForest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "crossValidation(svm_classifier, x_train_df, y_train_df)\n",
    "crossValidation(knn_classifier, x_train_df, y_train_df)\n",
    "crossValidation(catBoost_classifier, x_train_df, y_train_df)\n",
    "crossValidation(randomForest_classifier, x_train_df, y_train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm - 92.82% <br/>\n",
    "knn - nan% <br/>\n",
    "catBoost - 84.45% <br/>\n",
    "random forrest - 84.96% <br/>\n",
    "Therefore SVM is the best classifier to use further stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After dimension reduction (with PCA) cross validation and checking accuracy\n",
    "crossValidation(svm_classifier, x_train_df_pca, y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the previous observation, the accuracy has not significantly decreased even though PCA has been applied. Therefore, the dataset that underwent PCA is being used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning with random search \n",
    "best_params_from_random_search = randomSearch('svm', x_train_df_pca, y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search selects the best hyper-parameters for the chosen classifier randomly. Using these parameters, create a suitable parameter grid for grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning with grid search \n",
    "param_dist_svm = generate_param_grid(best_params_from_random_search, 'svm')\n",
    "print(param_dist_svm)\n",
    "# gridSearch('svm', param_dist_svm, svm_classifier, x_train_df_pca, y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination of random search followed by grid search strikes a balance between exploration and exploitation of the hyperparameter space, making hyperparameter tuning more efficient and effective in finding good model configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = svm.SVC(kernel='poly', C=100, gamma='scale', degree=3, class_weight='balanced')\n",
    "\n",
    "y_test_pred = modelTrain(svm_classifier, x_train_df_pca, y_train_df, x_valid_df_pca, y_valid_df, x_test_df_pca)\n",
    "\n",
    "all_labels.append(y_test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_from_labels(all_labels, 'layer7_output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
